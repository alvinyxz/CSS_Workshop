# Step 2: Load required libraries
library("text2vec")
library("wordVectors")
library("tidyverse")
install.packages("wordVectors") # For loading Word2Vec models
install.packages("devtools")
devtools::install_github("bmschmidt/wordVectors")
# Step 2: Load required libraries
library("text2vec")
library("wordVectors")
library("tidyverse")
# Step 3: Download pre-trained Word2Vec model (GloVe or FastText can be loaded similarly)
# Example uses GoogleNews-vectors-negative300.bin, a popular Word2Vec model
download.file("https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz", destfile = "GoogleNews-vectors.bin.gz")
# Step 4: Load pre-trained Word2Vec model into R
unzip("GoogleNews-vectors-negative300-SLIM.gz")
# Step 4: Load pre-trained Word2Vec model into R
unzip("GoogleNews-vectors-negative300-SLIM.bin.gz")
# Step 4: Load pre-trained Word2Vec model into R
unzip('/Users/alvinzhou/Library/CloudStorage/GoogleDrive-alvinyxz@umn.edu/My Drive/Teaching/CSS_Workshop/2025/CSS_Workshop/Day3/Lab/GoogleNews-vectors-negative300-SLIM.bin.gz')
# Step 4: Load pre-trained Word2Vec model into R
model <- read.vectors("GoogleNews-vectors-negative300-SLIM.gz", binary = TRUE)
# Step 4: Load pre-trained Word2Vec model into R
model <- read.vectors("GoogleNews-vectors-negative300-SLIM.bin", binary = TRUE)
# Step 5: Explore the loaded model
summary(model)
head(rownames(model)) # View some of the words in the embedding
# Step 6: Find similar words
similar_words <- closest_to(model, "king")
print(similar_words)
# Step 7: Compute analogy (e.g., king - man + woman = ?)
analogy_result <- model %>% closest_to(model[["king"]] - model[["man"]] + model[["woman"]])
print(analogy_result)
model %>% closest_to(model[["king"]] - model[["man"]] + model[["woman"]])
# Step 7: Compute analogy (e.g., king - man + woman = ?)
analogy_result <- closest_to(model, model[["king"]] - model[["man"]] + model[["woman"]])
# Step 7: Compute analogy (e.g., king - man + woman = ?)
analogy_result <- closest_to(model,  ~"king"-"man"+"woman")
print(analogy_result)
analogy_result <- closest_to(model,  ~"guy"-"man"+"woman")
print(analogy_result)
# Step 8: Visualizing word embeddings using t-SNE and ggplot2
library("Rtsne")
library("ggplot2")
# Select a few words to visualize
words_to_plot <- model[[c("king", "queen", "man", "woman", "dog", "cat")]]
words_matrix <- as.matrix(words_to_plot)
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 2)
words_matrix
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 2)
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 2, perplexity = 30)
print(words_matrix)
# Select a few words to visualize
words_to_plot <- model[c("king", "queen", "man", "woman", "dog", "cat")]
words_matrix <- as.matrix(words_to_plot)
print(words_matrix)
# Select a few words to visualize
words_to_plot <- model[[c("king", "queen", "man", "woman", "dog", "cat")]]
model
# Select a few words to visualize
words_to_plot <- model[[c("king", "queen", "man", "woman", "dog", "cat")]]
words_to_plot
# Select a few words to visualize
words_to_plot <- model[[c("king", "queen", "man", "woman", "dog", "cat")],]
model
# Select a few words to visualize
words_to_plot <- model[c("king", "queen", "man", "woman", "dog", "cat"), ]
words_matrix <- as.matrix(words_to_plot)
words_matrix
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 2)
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 2, perplexity = 2)
dim(words_matrix)
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 1, perplexity = 2)
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 2, perplexity = 2)
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 2, perplexity = 6)
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 2, perplexity = 1)
# Create a dataframe for ggplot
tsne_df <- data.frame(x = tsne_model$Y[, 1], y = tsne_model$Y[, 2], word = rownames(words_to_plot))
# Plot using ggplot2
ggplot(tsne_df, aes(x, y, label = word)) +
geom_text(size = 5) +
ggtitle("Word Embeddings t-SNE Visualization") +
theme_minimal()
# Select a few words to visualize
words_to_plot <- model[c("king",
"queen",
"man",
"woman",
"dog",
"cat",
"house",
"apartment",
"undergraduate",
"graduate"), ]
words_matrix <- as.matrix(words_to_plot)
# Perform t-SNE dimensionality reduction
tsne_model <- Rtsne(words_matrix, dims = 2, perplexity = 2)
# Create a dataframe for ggplot
tsne_df <- data.frame(x = tsne_model$Y[, 1], y = tsne_model$Y[, 2], word = rownames(words_to_plot))
# Plot using ggplot2
ggplot(tsne_df, aes(x, y, label = word)) +
geom_text(size = 5) +
ggtitle("Word Embeddings t-SNE Visualization") +
theme_minimal()
