{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of the GoogleNews-vectors-negative300-SLIM.bin in R, which we downloaded locally\n",
    "# We will now use the GloVe model from gensim, which you do not need to download but simply load from the cloud\n",
    "\n",
    "# Install the GloVe model using the gensim downloader\n",
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "300\n",
      "[-0.29784   -0.13255   -0.14505   -0.22752   -0.027429   0.11005\n",
      " -0.039245  -0.0089607 -0.18866   -1.1213   ]\n",
      "[('queen', 0.6336469054222107), ('prince', 0.6196622252464294), ('monarch', 0.5899620652198792)]\n"
     ]
    }
   ],
   "source": [
    "# See how many words are in the model\n",
    "print(len(model.key_to_index)) # 400000 words\n",
    "print(model.vector_size) # 300 dimensions (aka, each word is represented by 300 numbers)\n",
    "\n",
    "# See what's the vector for the word \"man\"\n",
    "# Only showing the first 10 numbers of the vector\n",
    "print(model[\"man\"][:10])\n",
    "\n",
    "# See the most similar three words to \"king\"\n",
    "print(model.most_similar(\"king\", topn=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to democracy: [('freedom', 0.6147063970565796), ('democratic', 0.547559916973114), ('dictatorship', 0.5458731055259705), ('freedoms', 0.5321065783500671), ('democratization', 0.5320093631744385)]\n",
      "Most similar to freedom: [('freedoms', 0.6644782423973083), ('liberty', 0.6439749002456665), ('democracy', 0.6147063970565796), ('rights', 0.609053373336792), ('liberties', 0.5701642036437988)]\n",
      "Most similar to liberty: [('freedom', 0.6439749002456665), ('equality', 0.4726463258266449), ('rights', 0.4273204207420349), ('freedoms', 0.42315995693206787), ('democracy', 0.41124075651168823)]\n"
     ]
    }
   ],
   "source": [
    "# Find nearest words to a list of words\n",
    "words = [\"democracy\", \"freedom\", \"liberty\"]\n",
    "for word in words:\n",
    "    print(f\"Most similar to {word}:\", model.most_similar(word, topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.6713277101516724)]\n"
     ]
    }
   ],
   "source": [
    "# Let's check relationships between words\n",
    "# king - man + woman â‰ˆ ?\n",
    "print(model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1))\n",
    "# Correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('japan', 0.7686553597450256)]\n"
     ]
    }
   ],
   "source": [
    "# Let's check relationships between words\n",
    "# china - beijing + tokyo â‰ˆ ?\n",
    "print(model.most_similar(positive=[\"china\", \"tokyo\"], negative=[\"beijing\"], topn=1))\n",
    "# Correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('frankfurt', 0.739791989326477)]\n"
     ]
    }
   ],
   "source": [
    "# Let's check relationships between words\n",
    "# tokyo - japan + germany â‰ˆ ?\n",
    "print(model.most_similar(positive=[\"tokyo\", \"germany\"], negative=[\"japan\"], topn=1))\n",
    "# Hmmm...\n",
    "# If you were thinking about: Tokyo is the capital of Japan, and Berlin is the capital of Germany\n",
    "# Then the model's answer is wrong\n",
    "# If you were thinking about: Tokyo is the financial hub of Japan, and Frankfurt is the financial hub of Germany\n",
    "# Then the model's answer is correct\n",
    "# This shows that the model captures different relationships based on the context of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between Beijing and China: 0.773\n",
      "Cosine similarity between Beijing and Chair: 0.104\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity between \"beijing\" and \"china\"\n",
    "similarity = model.similarity('beijing', 'china')\n",
    "print(f\"Cosine similarity between Beijing and China: {similarity:.3f}\")\n",
    "# Cosine similarity between \"beijing\" and \"chair\"\n",
    "similarity = model.similarity('beijing', 'chair')\n",
    "print(f\"Cosine similarity between Beijing and Chair: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if a word is in the vocabulary\n",
    "print(\"ðŸ§ª\" in model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
