{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04df502d",
   "metadata": {},
   "source": [
    "# Comment Classification in Python\n",
    "\n",
    "This notebook mirrors the `Classification.R` script and shows how to build a text classifier in Python.\n",
    "\n",
    "In Python, the most common libraries for text classification are `scikit-learn` and `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87007487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages (uncomment if needed)\n",
    "# !pip install pandas scikit-learn matplotlib seaborn nltk\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68016072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alvinzhou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords') # download stopwords dictionary so that we can later remove them from the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09033ee9",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8385ac91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled data shape: (600, 2)\n",
      "Test data shape: (1500, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You obviously need lessons in English. Go get ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deletion review for Bezgovo cvrtje\\nAn editor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agree.  Thanks for the clarification.  Have re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go fuck yourself in a corner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chavez sure isnt a hero. He's classic scum. An...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  You obviously need lessons in English. Go get ...      1\n",
       "1  Deletion review for Bezgovo cvrtje\\nAn editor ...      0\n",
       "2  Agree.  Thanks for the clarification.  Have re...      0\n",
       "3                       go fuck yourself in a corner      1\n",
       "4  Chavez sure isnt a hero. He's classic scum. An...      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df = pd.read_csv(\"comments_labeled.csv\")\n",
    "test_df = pd.read_csv(\"comments_test.csv\")\n",
    "print(\"Labeled data shape:\", labeled_df.shape)\n",
    "# The labeled_df contains 600 rows (comments) and 2 columns (text, label)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "# The test_df contains 1500 rows (comments) and 1 column (text), without labels\n",
    "# Display the first few rows of the labeled DataFrame\n",
    "labeled_df.head()\n",
    "# You can see that the 1st, 4th, and 5th comments are uncivil (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3843028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    300\n",
      "0    300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(labeled_df['label'].value_counts())\n",
    "# \"value_counts\" counts the number of occurrences of each label in the \"label\" column\n",
    "# The output shows that there are 300 uncivil comments (1) and 300 civil comments (0)\n",
    "# Which is a 50%/50% balanced distribution between civil (0) and uncivil (1) comments\n",
    "# This is not common: most datasets are imbalanced\n",
    "# In those cases, you would need to use techniques like oversampling, undersampling, or using specialized algorithms that handle imbalance\n",
    "# You can read: https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501624e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\\n\\n Best of Eurovision article \\n\\nThe event...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Range Block \\n\\nYour mom has good ass meat!! 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>==Time constraint== \\n The article text says 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hanibal911You're a bastard Pro-Assad. The rebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\n\\nNoel Coward claimed that the melody can b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  \"\\n\\n Best of Eurovision article \\n\\nThe event...\n",
       "1  Range Block \\n\\nYour mom has good ass meat!! 7...\n",
       "2  ==Time constraint== \\n The article text says 4...\n",
       "3  Hanibal911You're a bastard Pro-Assad. The rebe...\n",
       "4  \"\\n\\nNoel Coward claimed that the melody can b..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n",
    "# We will apply our selected/final model to this data in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9695237",
   "metadata": {},
   "source": [
    "## Preprocessing and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56db0cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 5350)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The stopwords are common words that do not contribute much to the meaning of a sentence, such as \"the\", \"is\", \"in\", etc.\n",
    "# We will remove these, as well as punctuation, from the text data to focus on the more meaningful words.\n",
    "stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "\n",
    "# Define a preprocessing function to clean the text data, where we will:\n",
    "# 1. Convert text to lowercase\n",
    "# 2. Remove stopwords and punctuation\n",
    "def preprocess(text):\n",
    "    return ' '.join([word.lower() for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column of both labeled and test DataFrames\n",
    "labeled_df['clean_text'] = labeled_df['text'].astype(str).apply(preprocess)\n",
    "test_df['clean_text'] = test_df['text'].astype(str).apply(preprocess)\n",
    "\n",
    "# Now we will convert the cleaned text data into numerical features using TF-IDF vectorization.\n",
    "# See the R script for detailed explanation of TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(labeled_df['clean_text'])\n",
    "y = labeled_df['label'].astype(int)\n",
    "\n",
    "X.shape\n",
    "# The X is a TF-IDF matrix with 600 rows (comments) and 5350 features equal to the number of unique words in the corpus that characterize the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6e63158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1621)\t0.415216366186908\n",
      "  (0, 2462)\t0.415216366186908\n",
      "  (0, 4066)\t0.337642473054448\n",
      "  (0, 2117)\t0.22242051418862424\n",
      "  (0, 2142)\t0.22669270755179363\n",
      "  (0, 1717)\t0.30965454032618644\n",
      "  (0, 2838)\t0.415216366186908\n",
      "  (0, 3233)\t0.26134537243753764\n",
      "  (0, 3361)\t0.3220805199217471\n",
      "  (1, 3493)\t0.1667559992668437\n",
      "  (1, 5131)\t0.10025708040637957\n",
      "  (1, 3076)\t0.11401780905924383\n",
      "  (1, 2577)\t0.1667559992668437\n",
      "  (1, 3445)\t0.14432863568065718\n",
      "  (1, 2631)\t0.08790599777855954\n",
      "  (1, 1416)\t0.12244704976322628\n",
      "  (1, 4462)\t0.1484088930555122\n",
      "  (1, 3471)\t0.15710989583257096\n",
      "  (1, 1534)\t0.12084235972526147\n",
      "  (1, 1063)\t0.1591412621858893\n",
      "  (1, 4342)\t0.11654060081391625\n",
      "  (1, 528)\t0.13236491527057534\n",
      "  (1, 1653)\t0.12794311407118808\n",
      "  (1, 1329)\t0.3549767367944417\n",
      "  (1, 707)\t0.3549767367944417\n",
      "  :\t:\n",
      "  (597, 939)\t0.07244238331674338\n",
      "  (597, 3523)\t0.04721447419994178\n",
      "  (598, 1581)\t0.3904380621932054\n",
      "  (598, 5274)\t0.3904380621932054\n",
      "  (598, 5272)\t0.3904380621932054\n",
      "  (598, 4848)\t0.32646917169891654\n",
      "  (598, 4285)\t0.3668290480147177\n",
      "  (598, 5307)\t0.35007818587740414\n",
      "  (598, 3174)\t0.2410887728549525\n",
      "  (598, 5326)\t0.19746297553399525\n",
      "  (598, 4647)\t0.28610929538311525\n",
      "  (599, 2374)\t0.3403110085359747\n",
      "  (599, 2019)\t0.3403110085359747\n",
      "  (599, 1338)\t0.3197330777356587\n",
      "  (599, 2785)\t0.24937666762408048\n",
      "  (599, 3387)\t0.25379261873486053\n",
      "  (599, 5249)\t0.30513280348018557\n",
      "  (599, 4167)\t0.26995459842439645\n",
      "  (599, 2145)\t0.24531438639041003\n",
      "  (599, 4757)\t0.2045941619880396\n",
      "  (599, 2045)\t0.20287361003312415\n",
      "  (599, 1954)\t0.2163584235190237\n",
      "  (599, 4817)\t0.1811802184632346\n",
      "  (599, 5167)\t0.29380795094501844\n",
      "  (599, 4313)\t0.25379261873486053\n"
     ]
    }
   ],
   "source": [
    "# Print out the X to see how the TF-IDF matrix looks like\n",
    "print(X)\n",
    "# For the first row/comment, which is \"You obviously need lessons in English. Go get some you ridiculous illiterate dunce.\"\n",
    "# We can expect the its TF-IDF vector to have non-zero values for the words \"obviously\", \"need\", \"lessons\", \"english\", \"ridiculous\", etc.\n",
    "# \"(0, 1621) 0.415216366186908\" means that the first row's 1621st column/feature/word has a TF-IDF value of 0.415216366186908\n",
    "# And all the values from the 1st column to the 1620th column are zero, meaning that those words do not appear in the first comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8b096",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15dcaa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: (480, 5350)\n",
      "Validation size: (120, 5350)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2025)\n",
    "# The above line splits the data into training and validation sets, with 80% of the data used for training and 20% for validation.\n",
    "# The random_state parameter ensures that the split is reproducible.\n",
    "print(\"Training size:\", X_train.shape)\n",
    "# We use 480 comments/rows for training\n",
    "print(\"Validation size:\", X_val.shape)\n",
    "# We use 120 comments/rows for validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8101a4",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cffddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89        60\n",
      "           1       0.91      0.85      0.88        60\n",
      "\n",
      "    accuracy                           0.88       120\n",
      "   macro avg       0.89      0.88      0.88       120\n",
      "weighted avg       0.89      0.88      0.88       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Logistic Regression\n",
    "# ================================\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "logistic_preds = logistic_model.predict(X_val)\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_val, logistic_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2599c6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82        60\n",
      "           1       0.80      0.88      0.84        60\n",
      "\n",
      "    accuracy                           0.83       120\n",
      "   macro avg       0.84      0.83      0.83       120\n",
      "weighted avg       0.84      0.83      0.83       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# K-Nearest Neighbors\n",
    "# ================================\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_preds = knn_model.predict(X_val)\n",
    "print(\"K-Nearest Neighbors Results:\")\n",
    "print(classification_report(y_val, knn_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43120a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88        60\n",
      "           1       0.94      0.78      0.85        60\n",
      "\n",
      "    accuracy                           0.87       120\n",
      "   macro avg       0.88      0.87      0.87       120\n",
      "weighted avg       0.88      0.87      0.87       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Support Vector Machine\n",
    "# ================================\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_preds = svm_model.predict(X_val)\n",
    "print(\"Support Vector Machine Results:\")\n",
    "print(classification_report(y_val, svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "517da046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.63      0.75        60\n",
      "           1       0.72      0.93      0.81        60\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.81      0.78      0.78       120\n",
      "weighted avg       0.81      0.78      0.78       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Random Forest\n",
    "# ================================\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict(X_val)\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_val, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a43894",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "So now, we have trained four different classifiers:\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbors (KNN)\n",
    "3. Support Vector Machine (SVM)\n",
    "4. Random Forest\n",
    "\n",
    "Based on the results, which model do you think performs the best? Select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68dc2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rf_model  # Assuming Random Forest performed best based on the classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f8bd3",
   "metadata": {},
   "source": [
    "## Predict on Test Data with Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ffc9d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\\n\\n Best of Eurovision article \\n\\nThe event...</td>\n",
       "      <td>best eurovision article event took place hambu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Range Block \\n\\nYour mom has good ass meat!! 7...</td>\n",
       "      <td>range block mom good ass meat!! 70.251.71.245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>==Time constraint== \\n The article text says 4...</td>\n",
       "      <td>==time constraint== article text says 4.5 hour...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hanibal911You're a bastard Pro-Assad. The rebe...</td>\n",
       "      <td>hanibal911you're bastard pro-assad. rebels ale...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\n\\nNoel Coward claimed that the melody can b...</td>\n",
       "      <td>noel coward claimed melody traced back old eng...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \"\\n\\n Best of Eurovision article \\n\\nThe event...   \n",
       "1  Range Block \\n\\nYour mom has good ass meat!! 7...   \n",
       "2  ==Time constraint== \\n The article text says 4...   \n",
       "3  Hanibal911You're a bastard Pro-Assad. The rebe...   \n",
       "4  \"\\n\\nNoel Coward claimed that the melody can b...   \n",
       "\n",
       "                                          clean_text  predicted_label  \n",
       "0  best eurovision article event took place hambu...                0  \n",
       "1      range block mom good ass meat!! 70.251.71.245                1  \n",
       "2  ==time constraint== article text says 4.5 hour...                0  \n",
       "3  hanibal911you're bastard pro-assad. rebels ale...                0  \n",
       "4  noel coward claimed melody traced back old eng...                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectorizer.transform(test_df['clean_text'])\n",
    "test_preds = best_model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "test_df['predicted_label'] = test_preds\n",
    "test_df[['predicted_label', 'text']].to_csv(\"comments_test_predictions_Python.csv\", index=False)\n",
    "test_df.head()\n",
    "\n",
    "# You can go to your working directory and find the file comments_test_predictions_Python.csv with the predictions.\n",
    "# Open it, and see if the labels make sense.\n",
    "# You will find some are misclassified, but many are correct (hopefully)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
